---
layout: default
title: Home
---

<div class="page">
  <p> 
<center><img src="https://github.com/cabooster/UDMT/blob/main/images/logo_blue.png?raw=true" width="700" align="middle" /></center>
</p>

  
  <header>
    <h1 class="landing-title"> UDMT: Unsupervised multi-animal tracking for quantitative ethology </h1>
  </header>


  <p>
  <center><h1>1. Basic principle </h1></center>
Quantitative ethology necessitates accurate tracking of animal locomotion, especially for population-level analyses involving multiple individuals. However, current methods rely on laborious annotations for supervised training and have restricted performance in challenging conditions. Here we present an <b>unsupervised deep-learning method for multi-animal tracking (UDMT)</b> that achieves state-of-the-art performance without requiring human annotations. By synergizing a bidirectional closed-loop tracking strategy, a spatiotemporal transformer network, and three sophisticatedly designed modules for localization refining, bidirectional ID correction, and automatic parameter tuning, UDMT can track multiple animals accurately in various challenging conditions, such as crowding, occlusion, rapid motion, low contrast, and cross-species experiments. 
   <br><br>
    <center><img src="https://github.com/cabooster/UDMT/blob/main/images/schematic.png?raw=true" width="850" align="middle" /></center>
    </p>
  <br> 
  
<hr>
   <p>
     
 <br><br>
  </p>
     <img src="https://github.com/cabooster/UDMT/blob/main/images/udmt2.png?raw=true" width="460" align="left">
 <h3>   <a href='https://www.biorxiv.org/content/10.1101/2022.03.14.484230v1'>Paper</a> | <a href='https://github.com/cabooster/DeepCAD-RT'>Code</a> </h3>
<h3>Tracking in a completely unsupervised manner:</h3>
UDMT does not require any human annotations for training. The only thing users need to do is to click the animals in the first frame to specify the individuals they want to track. 
<br><h3>Spatiotemporal transformer for better feature extraction:</h3>
To better capture the spatiotemporal evolution of animal features more effectively, we incorporated a spatiotemporal transformer network (ST-Net) to utilize self-attention and cross-attention mechanisms for feature extraction, leading to a threefold reduction in IDSW compared with convolutional neural networks (CNNs).
<br><h3>Three key modules for performance optimization:</h3>
We designed three critical functional modules to solve the inherent performance degradation by localization refining, bidirectional ID correction, and automatic parameter tuning.
 <br>
  
  <p>
    <br>
    <center><h2>Real-time implementation </h2></center>

  To achieve real-time processing during imaging acquisition, we made a program interface to incorporate DeepCAD-RT into our image acquisition software (Scanimage 5.7, Vidrio Technologies). For further acceleration and memory conservation, the inference of DeepCAD-RT was optimally deployed on GPU with TensorRT (NVIDIA), programmed in C++ for best hardware interaction, and then compiled in Matlab (MathWorks). Three parallel threads were designed for imaging, data processing, and display. The schedule for multi-thread programming is depicted in the following figure. The real-time implementation of DeepCAD-RT has been packaged as a free plugin with a user-friendly interface, and it could also be called by a Matlab script.
  </p>
  <p>
  <center><img src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/deepcad5.png?raw=true" width="950" align="middle" /></center>
   </p>
  
  <br> 
  <a href="https://www.nature.com/articles/s41587-022-01450-8"><img src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/deepcadrt3r.png?raw=true" width="300" align="left"/></a>
 <h3>Paper</h3>
<p>Nature Biotechnology, 2022. </p>
<h3>Citation</h3>
<p>Li, X., Li, Y., Zhou, Y. et al. Real-time denoising enables high-sensitivity fluorescence time-lapse imaging beyond the shot-noise limit. Nat Biotechnol (2022). <a href="https://www.nature.com/articles/s41587-022-01450-8">https://doi.org/10.1038/s41587-022-01450-8</a>
</p>
  <h3>Code: <a href='https://github.com/cabooster/DeepCAD-RT'>PyTorch</a> | <a href='https://github.com/cabooster/DeepCAD-RT/tree/main/DeepCAD_RT_GUI'>Matlab</a>   </h3>
  <br> <br>
  
  
  <hr>
    <center><h1>2. Application and Results </h1></center>
 We demonstrate the state-of-the-art performance of UDMT on five different kinds of model animals, including mice, rats, Drosophila, C. elegans, and Betta splendens. Combined with a head-mounted miniaturized microscope, we recorded the calcium transients synchronized with mouse locomotion to decipher the correlations between animal locomotion and neural activity.More details please refer to <a href=' '>the companion paper</a>.
  <center><h2> Tracking the movement of 10 mice simultaneously with UDMT </h2></center>
  <center><iframe width="850" height="450" src="https://www.youtube.com/embed/yFT3AdmNVg8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </center>
<br>
  <center><h2> Neuroethology analysis of multiple mice combined with a head-mounted microscope </h2></center>
  <center><iframe width="850" height="450" src="https://www.youtube.com/embed/zufYK1ovlLU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center>
<br>
 <center> <h2> Analyzing the aggressive behavior of betta fish with UDMT</h2></center>
 <center> <iframe width="850" height="450" src="https://www.youtube.com/embed/z724dDa0CRM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center>

  
  
    <p>
      <br><br><br><center>For more information, you can visit following sub-pages:</center>
    <div nowrap align="center"><a href='https://cabooster.github.io/UDMT/About/'>About</a> | <a href='https://cabooster.github.io/UDMT/Tutorial/'>Tutorial</a> | <a href='https://cabooster.github.io/UDMT/Datasets/'>Datasets</a> | <a href='https://cabooster.github.io/UDMT/Gallery/'>Gallery</a></div>
    </p>


  
   

</div>


